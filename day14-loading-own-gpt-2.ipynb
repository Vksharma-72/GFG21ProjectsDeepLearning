{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Assignment: Code-Focused Inference\n\nYour task is to load a pre-trained GPT-2 model and configure it to answer *only* questions related to Python coding.\n\n1. **Load Model and Tokenizer:** Load a suitable pre-trained GPT-2 model and its corresponding tokenizer. You can use `transformers.AutoModelForCausalLM` and `transformers.AutoTokenizer`. A smaller model like `gpt2` or `gpt2-medium` might be sufficient.\n2. **Implement a Filtering Mechanism:** Before generating a response, check if the input prompt is related to Python coding. You can use simple keyword matching (e.g., \"Python\", \"code\", \"function\", \"class\", \"import\") or a more sophisticated approach using a text classification model (optional).\n3. **Generate Response:** If the prompt is deemed a Python coding question, generate a response using the loaded GPT-2 model.\n4. **Handle Non-Coding Questions:** If the prompt is not related to Python coding, return a predefined message indicating that the model can only answer coding questions.\n5. **Test:** Test your implementation with various prompts, including both Python coding questions and non-coding questions, to ensure the filtering mechanism works correctly.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:22:55.810376Z","iopub.execute_input":"2025-09-21T17:22:55.810809Z","iopub.status.idle":"2025-09-21T17:23:21.076758Z","shell.execute_reply.started":"2025-09-21T17:22:55.810782Z","shell.execute_reply":"2025-09-21T17:23:21.075985Z"}},"outputs":[{"name":"stderr","text":"2025-09-21 17:23:08.050665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758475388.227898      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758475388.280433      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 1. Loading Models and Tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = \"gpt2\"  \nmodel_name2 = \"gpt2-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer2 = AutoTokenizer.from_pretrained(model_name2)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\nmodel2 = AutoModelForCausalLM.from_pretrained(model_name2)\n\n\n# Build pipeline for convenience\ngenerator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer ) #, device=0 if torch.cuda.is_available() else -1)\ngenerator2 = pipeline(\"text-generation\", model=model2, tokenizer=tokenizer)  # , device=0 if torch.cuda.is_available() else -1) this code if for my gpu use but this time i using kaggle\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:23:25.628493Z","iopub.execute_input":"2025-09-21T17:23:25.629475Z","iopub.status.idle":"2025-09-21T17:23:48.926953Z","shell.execute_reply.started":"2025-09-21T17:23:25.629444Z","shell.execute_reply":"2025-09-21T17:23:48.926270Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1105cf4729c649c0815e328cc50acd95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa6d394b1b54c139b170a076b89cdf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ebb87ae50844193be7b09524d4088fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76353ece7bbf4bbf94d9e5a5ed690a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f2607f774ec4cca8df95ada7fcc4e36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57fb1f99a7464a429e95bb19250b936d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7daeeb9871e14a468c08e003e78e2ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b8e573eff2449caa28e51c8c426077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543ed621449a4ce0b63d1e53b75cba75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f656e484237b4fe3a7c399eb9f42d5fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ff1d790a304be8afec0351ac6aa2ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf21b7ba929e436cbde1b99e3ef237a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769fa0b5bcc84830951a2dd1d924d041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8a1d2d6d822415d853669ca09908b61"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 2. Filtering mechanism (simple keyword-based)","metadata":{}},{"cell_type":"code","source":"def is_python_question(prompt: str) -> bool:\n    keywords = [\"python\", \"code\", \"function\", \"class\", \"import\", \"def\", \"list\", \"dict\"]\n    prompt_lower = prompt.lower()\n    return any(keyword in prompt_lower for keyword in keywords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:23:48.928021Z","iopub.execute_input":"2025-09-21T17:23:48.928310Z","iopub.status.idle":"2025-09-21T17:23:48.932726Z","shell.execute_reply.started":"2025-09-21T17:23:48.928281Z","shell.execute_reply":"2025-09-21T17:23:48.932188Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 3. Generate response if coding related, else return fallback","metadata":{}},{"cell_type":"code","source":"def code_focused_inference(prompt: str, max_length: int = 150):\n    if is_python_question(prompt):\n        response = generator(prompt, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n        return response[0][\"generated_text\"]\n    else:\n        return \"⚠️ This model only answers Python coding-related questions.\"\n\ndef code_focused_inference2(prompt: str, max_length: int = 150):\n    if is_python_question(prompt):\n        response = generator2(prompt, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n        return response[0][\"generated_text\"]\n    else:\n        return \"⚠️ This model only answers Python coding-related questions.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:23:48.933345Z","iopub.execute_input":"2025-09-21T17:23:48.933563Z","iopub.status.idle":"2025-09-21T17:23:49.752407Z","shell.execute_reply.started":"2025-09-21T17:23:48.933537Z","shell.execute_reply":"2025-09-21T17:23:49.751621Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 4. Testing with different inputs","metadata":{}},{"cell_type":"code","source":"test_prompts = [\n    \"Write a Python function to reverse a string.\",\n    \"What is the capital of France?\",\n    \"Show me how to import pandas and create a DataFrame.\",\n    \"Who won the World Cup in 2018?\",\n    \"Give me list of python Data Structure ?\",\n    \"Who is the owner of Tesla\",\n    \"What is the meaning of list in python\",\n    \"What is Youtube\",\n    \"Who created the Python coding language and when\"\n    \n]\n\nfor prompt in test_prompts:\n    print(f\"Prompt: {prompt}\")\n    print('----'*20)\n    print(f\"Response: {code_focused_inference(prompt)}\\n\")\n    print('----'*20)\n    print(f\"Response2: {code_focused_inference2(prompt)}\\n\")\n    print('----'*20)\n    print('----'*20)\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T17:25:13.044171Z","iopub.execute_input":"2025-09-21T17:25:13.044708Z","iopub.status.idle":"2025-09-21T17:25:43.519141Z","shell.execute_reply.started":"2025-09-21T17:25:13.044681Z","shell.execute_reply":"2025-09-21T17:25:43.518342Z"}},"outputs":[{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Prompt: Write a Python function to reverse a string.\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response: Write a Python function to reverse a string.\n\ndef reverse_string ( args ): return {'a': False, 'b': False}\n\nSo, let's say we have a pattern on a string, and a pattern of types \"a\", \"b\", and \"c\" on a string.\n\ndef reverse_pattern ( args ): from sqlite3 import ReverseString def get_pattern ( pattern ): if pattern.startswith( 'a' ): print \"%s\".format(pattern.strip() + \" \" + pattern.width) def get_pattern ( pattern ): print \"%s\".format(pattern.strip() + \" \" + pattern.width + \" \" + pattern.length) def get_pattern_or_strip ( pattern ): print \"%s\".format(pattern.strip() + \" \" + pattern.width) def get_pattern_or_strip_all ( pattern ): print \"%s\".format(pattern.strip() + \" \" + pattern.width + \" \" + pattern.length) def get_pattern_or_strip_all_all ( pattern ): print \"%s\".format(pattern.strip() + \" \" + pattern.width + \" \" + pattern.length) def get_pattern_\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response2: Write a Python function to reverse a string.\n\nA Python function that allows reversing pairs of strings.\n\nA Python function that turns a string into a list.\n\nA Python function that makes a list of the characters that you enter.\n\nA Python function that makes a list of the characters that you select.\n\nA Python function that makes a list of the characters that you change.\n\nA Python function that makes a list of the characters that you change.\n\nA Python function that makes a list of the characters that you insert.\n\nA Python function that makes a list of the characters that you insert.\n\nA Python function that makes a list of the characters that you change.\n\nA Python function that makes a list of the characters that you set.\n\nA Python function that makes a list of the characters that you set.\n\nA Python function that makes a list of the characters that you set.\n\nA Python function that makes a list of the characters that you check.\n\nA Python function that makes a list of the characters that you check.\n\nA Python function that makes a list of the characters that you check.\n\nA Python function that makes a list of the characters that you check.\n\nA Python function that makes\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: What is the capital of France?\n--------------------------------------------------------------------------------\nResponse: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\nResponse2: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: Show me how to import pandas and create a DataFrame.\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response: Show me how to import pandas and create a DataFrame.\n\nimport pandas as pd import pandas.core.model.DB import pandas.core.model.Constant class DataFrame () {\n\nreturn (\n\n<DataFrame a=\"{}\" b=\"{}\" />)\n\n}\n\n}\n\nOutput:\n\n{ \"id\" : \"828c1b-4f5b-4f66-ba55-0d20b5ca5b9\", \"title\" : \"Constant DataFrame\", \"version\" : \"0.10.0\", \"description\" : \"Constant DataFrame\", \"data\" : [ \"data:data\" ]\n\n}\n\nOutput:\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame.\n\nConstant DataFrame\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response2: Show me how to import pandas and create a DataFrame.\n\nimport pandas as pd import numpy as np d = pd. read_csv ( 'input.csv' ) # get row 1 df = d. read_csv ('result.csv' ) df. skip. append ( df [ 1 :]) df. skip. append ( df [ 2 ]) df. skip. append ( df [ 3 ]) # get row 2 df = d. read_csv ('result.csv' ) df. skip. append ( df [ 4 :]) df. skip. append ( df [ 5 ]) # end of result df. skip. append ( df [ 6 ]) # end of result df. skip. append ( df [ 7 ]) # end of result\n\nYou can use this on your own data.\n\nimport pd from pandas import DataFrame import data.frame as df from datetime import datetime import str, timedelta from datetime import timedelta as d t1 = df. read_csv ('result.csv' ) t2 = df. read_csv ('result.csv' ) # start with row 1 df. skip. append ( t1 ) df. skip. append ( t2 ) df. skip. append ( t3\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: Who won the World Cup in 2018?\n--------------------------------------------------------------------------------\nResponse: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\nResponse2: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: Give me list of python Data Structure ?\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response: Give me list of python Data Structure ?\n\nAnswer: There is a very simple way\n\nto use Data Structure in Python\n\nI use it to:\n\nGenerate a list of strings\n\nFind a list of strings (using Python 4)\n\nFind a list of strings (using Python 3)\n\nFind a list of strings (using Python 2)\n\nRead a list of strings (using Python 1)\n\nRead a list of strings (using Python 0)\n\nRead a list of strings (using Python 0)\n\nCheck if python 3.4 is using\n\n(Check if python 3.4 is using Python 2)\n\nI use Python 2 to check if python 3.4 is using Python 3.2\n\nI use Python 2 to check if python 3.2 is using Python 3.1\n\nI use Python 2 to check if python 3.1 is using python 3.0\n\nI use Python 2 to check if python 2 is using python 3.0\n\nI use Python 2 to check if python 2 is using Python 3.0\n\nI use Python 2 to check if python 2 is using python 3.0\n\nSo what do I do next?\n\nI do:\n\nCheck if Python\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\nBoth `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response2: Give me list of python Data Structure ?\n\nno, you can use simple one, not list.\n\nHow can I make my own list of python Data Structure?\n\nYou can use the standard Python list type class and get a list of lists:\n\n>>> import lists >>> list = lists.copy() >>> list.sort() >>> list.append(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']) >>> lists.contains(list) True >>> lists.contains(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']) False\n\nor you can use list.append() method instead:\n\n>>> list = lists.append(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: Who is the owner of Tesla\n--------------------------------------------------------------------------------\nResponse: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\nResponse2: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: What is the meaning of list in python\n--------------------------------------------------------------------------------\nResponse: What is the meaning of list in python?\n\nP.S. I used to call it \"List Manipulation\".\n\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response2: What is the meaning of list in python?\n\nThis is a collection of lists that we can sort.\n\nList sorted by length\n\nExamples:\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n[1, 2, 3, 4]\n\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: What is Youtube\n--------------------------------------------------------------------------------\nResponse: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\nResponse2: ⚠️ This model only answers Python coding-related questions.\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nPrompt: Who created the Python coding language and when\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Response: Who created the Python coding language and when did it become the most widely used and used programming language? In this talk, you'll learn about the origins of Python, and how it's evolved since then. You'll also learn about the Python programming language's potential and its future.\n\nWhat is the Python programming language?\n\nThe Python programming language is the Python programming language. Python is the Python programming language which is the code that is written for the Python programming language.\n\nThe Python programming language was written with the Python programming language in mind.\n\nTo understand the Python programming language, you will need to know:\n\nthe type system for Python\n\nthe type system for Python the number type system\n\nthe type system for Python the type system and the type system are the same\n\nThe type system of Python is an abstract type system.\n\nThe \"Python programming language\" is a set of abstract types, such as the Python type system.\n\nThe Python programming language is a set of abstract types, such as the Python type system. Python is a Python programming language.\n\nPython is a Python programming language.\n\nIt's the first class of programming languages designed to be a single, single language.\n\nPython is a single program, and for this reason\n\n--------------------------------------------------------------------------------\nResponse2: Who created the Python coding language and when?\n\nWhen Python was created, in 1975, it was already a popular programming language. As a result, when people tried to learn it they often ended up using the same set of tools and methods they used to learn C (such as the shell). The Python community is comprised of many people who have enjoyed learning Python. It is also worth mentioning that the Python community is largely self-selected, meaning that no one has ever been the sole administrator of a Python project.\n\nThe Python developers have been involved in every major Python version. The most significant development is the 2.6 version of Python, which was released in May 2008.\n\nThe Python developers had a number of different goals when developing Python. It is important to understand that the Python developers did not just try to make Python as easy to learn as possible. Python was designed to be a standard Python language, and as such is designed to be an incredibly powerful language. It is also important to realize that this is a standard language designed to be used by a wide range of people and for any number of different types of work.\n\nAs a result, the developers were not interested in making Python as easy to learn as possible, for one simple reason: it was hard to learn. Therefore,\n\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"##### The gpt-2 medium good result and exact result that we ask , gpt2 is give the response more that not ask or required ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}